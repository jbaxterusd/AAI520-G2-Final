{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Project Script  \n",
    "#Agentic AI for financial analysis \n",
    "#MODEL/CODE INSPO: https://python.langchain.com/docs/tutorials/agents/\n",
    "#xAI Integration: https://x.ai/api#capabilities\n",
    "#Agent Params/Structure: https://langchain-ai.github.io/langgraph/reference/agents/, \n",
    "#https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langgraph langchain-tavily langgraph-checkpoint-sqlite\n",
    "%pip install langchain-huggingface\n",
    "%pip install -qU langchain-xai\n",
    "%pip install yfinance\n",
    "%pip install nltk\n",
    "%pip install string\n",
    "%pip install transformers\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from datetime import datetime, timedelta \n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all API keys feel free to slack me! \n",
    "#If I post them here GitHub auto-revokes them due to user privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_API_KEY'] = getpass.getpass('Enter the API key for LangSmith: ')\n",
    "os.environ['TAVILY_API_KEY'] = getpass.getpass('Enter the API key for Tavily: ')\n",
    "os.environ['XAI_API_KEY'] = getpass.getpass('Enter API key for xAI: ')\n",
    "os.environ['FINNHUB_API_KEY'] = getpass.getpass('Enter API key for FinnHub: ')\n",
    "os.environ['ALPHAVANTAGE_API_KEY' ] = getpass.getpass('Enter API key for Alpha Vantage: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all necessary tools for agent/steps of project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Tavily search tool (general)\n",
    "search = TavilySearch(max_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt-chaining tools below:\n",
    "#def ingest_news (ingest)\n",
    "#def preproc_news (preprocess)\n",
    "#def classify_news (classify)\n",
    "#def extract_news (extract)\n",
    "#def summarize_news (summarize)\n",
    "#APIS used: finnhub, alpha vantage, yahoo finance\n",
    "\n",
    "#Emphasis on packages/methods used in prior assignments \n",
    "#packages used: HuggingFace, NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages and langchain integrations for prompt chaining \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import langchain_huggingface\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using yahoofinance to get news articles\n",
    "#symbol string param, fixed number of reports to retrieve \n",
    "def ingest_news(symbol,numart=10):\n",
    "    reports = []\n",
    "    name = yf.Ticker(symbol)\n",
    "    info = name.news[:numart]\n",
    "    for bit in info: \n",
    "        reports.append({\n",
    "            'headline': bit.get('title',''),\n",
    "            'article': bit.get('summary',''),\n",
    "            'time': bit.get('time_published', ''),\n",
    "            'source': bit.get('source', '')\n",
    "        })\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using nltk to preprocess news reports for analysis\n",
    "#list of report dicts param\n",
    "def preproc_news(reports):\n",
    "    def preproc_item(item):\n",
    "        lowercase = item.lower()\n",
    "        tokenized = word_tokenize(lowercase)\n",
    "        tokenized = [token for token in tokenized if token not in string.punctuation]\n",
    "        stopwords = set(stopwords.words('en'))\n",
    "        tokenized = [token for token in tokenized if token not in stopwords]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokenized = [stemmer.stem(token) for token in tokenized]\n",
    "        return tokenized \n",
    "    \n",
    "    preproc_reports = []\n",
    "    for report in reports: \n",
    "        preproc_report = report.copy()\n",
    "        preproc_report['preproc_headline'] = preproc_news(report.get('headline', ''))\n",
    "        preproc_report['preproc_article'] = preproc_news(report.get('article', ''))\n",
    "        preproc_reports.append(preproc_report)\n",
    "    \n",
    "    return preproc_reports\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using nltk to classify preprocessed reports \n",
    "#list of report dict params\n",
    "def classify_news(preproc_reports):\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    classified_reports = []\n",
    "    for report in preproc_reports: \n",
    "        headline = report.get('preproc_headline', '')\n",
    "        article = report.get('preproc_article', '')\n",
    "        comb = f'{headline} {article}'.strip()\n",
    "        scores = sentiment_analyzer.polarity_scores(comb)\n",
    "        compound = scores['compound']\n",
    "        if compound >= 0.5:\n",
    "            sentiment = 'positive'\n",
    "        elif compound <= -0.5:\n",
    "            sentiment = 'negative'\n",
    "        else: \n",
    "            sentiment = 'neutral'\n",
    "        classified_report = report.copy()\n",
    "        classified_report['sentiment'] = sentiment\n",
    "        classified_reports.append(classified_report)\n",
    "    return classified_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using huggingface NER to extract meaningful financial components of news reports\n",
    "#list of report dict params\n",
    "def extract_news(reports):\n",
    "    nerpretrain = 'dbmdz/bert-large-cased-finetuned-conll03-english'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(nermodel)\n",
    "    nermodel = AutoModelForTokenClassification.from_pretrained(nerpretrain)\n",
    "    nerpipe = pipeline('ner', model=nermodel,tokenizer=tokenizer,aggregation_strategy='simple',device=-1)\n",
    "    extra_reports = []\n",
    "    for report in reports: \n",
    "        headline = report.get('headline')\n",
    "        article = report.get('article')\n",
    "        comb = f'{headline} {article}'.strip()\n",
    "        rawent = nerpipe(comb)\n",
    "        entis = [(ent['word'],ent['entity_group'])for ent in rawent if ent['score'] > 0.5]\n",
    "        extract_report = report.copy()\n",
    "        extract_report['entis'] = entis\n",
    "        extra_reports.append(extract_report)\n",
    "    return extra_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the analysis gathered so far in the prompt-chain and report\n",
    "def summarize_news(reports):\n",
    "    newsdata = reports \n",
    "    preproc_reports = preproc_news(newsdata)\n",
    "    classified_reports = classify_news(preproc_reports)\n",
    "    extracted_reports = extract_news(classified_reports)\n",
    "    fintotal = len(extracted_reports)\n",
    "#sentiment summs \n",
    "    sentiments = [report['sentiment'] for report in extracted_reports]\n",
    "    sentiment_counts = Counter(sentiments)\n",
    "    sentiment_summary = {\n",
    "        'total_articles': fintotal,\n",
    "        'distribution': {\n",
    "            'positive': round((sentiment_counts['positive'] / fintotal) * 100, 2),\n",
    "            'negative': round((sentiment_counts['negative'] / fintotal) * 100, 2),\n",
    "            'neutral': round((sentiment_counts['neutral'] / fintotal) * 100, 2)\n",
    "        },\n",
    "        'counts': dict(sentiment_counts)\n",
    "    }\n",
    "#extract sums \n",
    "    all_ents = []\n",
    "    for report in extracted_reports:\n",
    "        all_ents.extend(report.get('entities', []))\n",
    "    entity_counter = Counter()\n",
    "    for entity_text, label in all_ents:\n",
    "        entity_counter[f\"{entity_text}:{label}\"] += 1\n",
    "    entity_by_type = {}\n",
    "    for key, count in entity_counter.most_common():\n",
    "        text, label = key.split(':', 1)\n",
    "        if label not in entity_by_type:\n",
    "            entity_by_type[label] = []\n",
    "        entity_by_type[label].append((text, count))\n",
    "    top_entities = {label: items[:5] for label, items in entity_by_type.items()}\n",
    "    entity_summary = {\n",
    "        'total_entities': len(all_ents),\n",
    "        'top_by_type': top_entities\n",
    "    }\n",
    "#overall sums \n",
    "    trends = {}\n",
    "    if 'time' in extracted_reports[0]: \n",
    "        monthly_sentiments = Counter()\n",
    "        for report in extracted_reports:\n",
    "            dt = datetime.strptime(report['time'], '%Y-%m-%d') \n",
    "            month_key = dt.strftime('%Y-%m')\n",
    "            monthly_sentiments[f\"{month_key}:{report['sentiment']}\"] += 1\n",
    "        monthly_summary = {}\n",
    "        for key, count in monthly_sentiments.items():\n",
    "            month, sent = key.split(':', 1)\n",
    "            if month not in monthly_summary:\n",
    "                monthly_summary[month] = Counter()\n",
    "            monthly_summary[month][sent] += count\n",
    "        trends = {'monthly_sentiment': monthly_summary}\n",
    "    return {\n",
    "        'sentiment_summary': sentiment_summary,\n",
    "        'entity_summary': entity_summary,\n",
    "        'trends': trends,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all tools for model/agent use\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define agent model for xai llm integration\n",
    "model = init_chat_model('grok-2',model_provider='xai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create memory\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a prompt for the agent role in our project \n",
    "agentrole = SystemMessage(\n",
    "    content='''You are an expert financial analysis agent. To start, ask user for stock symbol. Confirm the company, provide recent stock information. Gather \n",
    "    news with the ingest_news(), then preprocess with preproc_news(), classify with classify_news(), extract with extract_news() and summarize with summarize_news() \n",
    "    Allow room for user feedback, update at each step. \n",
    "    Next, ask user to specify your specialty as an analyst, \n",
    "    provide examples but accept all input (examples: earnings analyst, news analyst, market analyst, valuation, risk management, quant).\n",
    "    Tailor new response to speciality selected, Use tools, update user with visual and text strategies/reports. \n",
    "    Generate analysis, ask for feedback on quality, refine response if necessary.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the agent \n",
    "financeanalyst = create_react_agent(model,tools,prompt=agentrole,checkpointer=memory)\n",
    "config = {'configurable': {'thread_id': 'testingproj1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the USD-AAI Financial Advisor Agency!\n",
      "jbaxter25: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nif start == 'Y':\\n    while True: \\n        humaninput = input()\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt user to start and run agent while loop until exiting\n",
    "print('Welcome to the USD-AAI Financial Advisor Agency!')\n",
    "name = input('Please enter a username or nickname to begin: ')\n",
    "userid = name + ': '\n",
    "print(userid)\n",
    "startagent = input('Your personal financial agent is ready to go! Confirm (Y) to begin or (N) to exit: ')\n",
    "if startagent != 'Y':\n",
    "    print('Cancelled Agent Request')\n",
    "else:\n",
    "    print('Starting, to end/cancel your agent, simply input \"exit\" \"stop\" or \"cancel\"')\n",
    "    while True: \n",
    "        myinput = input(f\"{userid}\").strip()\n",
    "        if myinput in ['exit', 'stop', 'cancel']:\n",
    "            print('Agent Disconnected')\n",
    "            break\n",
    "        for step in financeanalyst.stream(\n",
    "            {\"messages\": [('user', myinput)]}, config, stream_mode='values'\n",
    "        ):\n",
    "            step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Jack\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Jack! To proceed with the financial analysis of CLPT (ClearPoint Neuro, Inc.), please confirm if this is the correct company. If you have another company in mind, please provide the stock symbol or the company name.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "CLPT\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The stock symbol CLPT represents ClearPoint Neuro, Inc. Is this the company you would like to analyze?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "YES\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I am retrieving the latest financial data for ClearPoint Neuro, Inc. (CLPT).\n",
      "Tool Calls:\n",
      "  tavily_search (call_92252751)\n",
      " Call ID: call_92252751\n",
      "  Args:\n",
      "    query: ClearPoint Neuro, Inc. financial performance\n",
      "    topic: finance\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"ClearPoint Neuro, Inc. financial performance\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://finance.yahoo.com/news/clearpoint-neuro-reports-first-quarter-204000224.html\", \"title\": \"ClearPoint Neuro Reports First Quarter 2025 Results\", \"content\": \"Total revenue was $8.5 million and $7.6 million for the three months ended March 31, 2025 and 2024, respectively, representing an increase of 11\", \"score\": 0.829285, \"raw_content\": null}, {\"url\": \"https://finance.yahoo.com/news/clearpoint-neuro-first-quarter-2025-110036645.html\", \"title\": \"ClearPoint Neuro First Quarter 2025 Earnings\", \"content\": \"ClearPoint Neuro (NASDAQ:CLPT) First Quarter 2025 Results. Key Financial Results. Revenue: US$8.49m (up 11% from 1Q 2024).\", \"score\": 0.8106142, \"raw_content\": null}], \"response_time\": 0.82, \"request_id\": \"2c449506-4a06-4b74-8db3-33c3c4834d4c\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The financial performance for ClearPoint Neuro, Inc. (CLPT) shows a total revenue of $8.5 million for the first quarter of 2025, which is an 11% increase from the first quarter of 2024. Would you like to know more details or have any other questions regarding CLPT or another company?\n"
     ]
    }
   ],
   "source": [
    "#start agent comms // prior loop\n",
    "'''intro = input('Enter your name to activate the finance agent: ')\n",
    "for step in financeanalyst.stream(\n",
    "    {\"messages\": [('user', intro)]}, config, stream_mode='values'\n",
    "):\n",
    "    step['messages'][-1].pretty_print()\n",
    "stocksymbol = input('Enter symbol here: $')\n",
    "for step in financeanalyst.stream(\n",
    "    {\"messages\": [('user', stocksymbol)]}, config, stream_mode='values'\n",
    "):\n",
    "    step['messages'][-1].pretty_print()\n",
    "confirmation = input('Enter YES if yes, Enter NO if no: ')\n",
    "for step in financeanalyst.stream(\n",
    "    {\"messages\": [('user', confirmation)]}, config, stream_mode='values'\n",
    "):\n",
    "    step['messages'][-1].pretty_print()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41358527d2f98e4cda843638694b690dd860ad47c9b0abc81c6dd2c00e6d110e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
